---
title: Dirichlet Bayesian Network Scores and the Maximum Entropy Principle
section: Invited Papers
abstract: "A classic approach for learning Bayesian networks from data is to select
  the\r \\emph{maximum a posteriori} (MAP) network. In the case of discrete Bayesian\r
  networks, the MAP network is selected by maximising one of several possible\r Bayesian
  Dirichlet (BD) scores; the most famous is the \\emph{Bayesian\r Dirichlet equivalent
  uniform} (BDeu) score from Heckerman \\emph{et al.} (1995). The key\r properties
  of BDeu arise from its underlying uniform prior, which makes\r structure learning
  computationally efficient; does not require the elicitation\r of prior knowledge
  from experts; and satisfies score equivalence.\r In this paper we will discuss the
  impact of this uniform prior on structure\r learning from an information theoretic
  perspective, showing how BDeu may\r violate the maximum entropy principle when applied
  to sparse data and how it\r may also be problematic from a Bayesian model selection
  perspective. On the\r other hand, the BDs score proposed in Scutari (2016) arises
  from a piecewise\r prior and it does not appear to violate the maximum entropy principle,
  even\r though it is asymptotically equivalent to BDeu."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: scutari17a
month: 0
tex_title: Dirichlet Bayesian Network Scores and the Maximum Entropy Principle
firstpage: 8
lastpage: 20
page: 8-20
order: 8
cycles: false
author:
- given: Marco
  family: Scutari
date: 2017-09-03
address: 
publisher: PMLR
container-title: Proceedings of The 3rd International Workshop on Advanced Methodologies
  for Bayesian Networks
volume: '73'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 9
  - 3
pdf: http://proceedings.mlr.press/v73/scutari17a/scutari17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
